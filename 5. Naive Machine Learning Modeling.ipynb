{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# h2o modules\n",
    "from h2o.frame import H2OFrame\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "# LightGBM modules\n",
    "import lightgbm as lgb\n",
    "\n",
    "# CatBoost modules\n",
    "from catboost import Pool, cv, CatBoostClassifier\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.options.display.max_rows = 100\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_clean.csv')\n",
    "test = pd.read_csv('./data/test_clean.csv')\n",
    "\n",
    "print('Train:')\n",
    "print(train.info(verbose=False), '\\n')\n",
    "print('Test:')\n",
    "print(test.info(verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced dataset\n",
    "target1 = train['target'].sum()\n",
    "target0 = (1 - train['target']).sum()\n",
    "\n",
    "print('Target 0:\\t', target0, '\\t', np.round(target0 / len(train), 4))\n",
    "print('Target 1:\\t', target1, '\\t', np.round(target1 / len(train), 4))\n",
    "print('0/1 Ratio:\\t', np.round(target0 / target1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categorical and numerical features\n",
    "cat_features = ['term', 'home_ownership', 'verification_status', 'purpose', \n",
    "                'title', 'addr_state', 'initial_list_status', 'application_type', \n",
    "                'grade', 'sub_grade']\n",
    "\n",
    "num_features = ['loan_amnt', 'loan_to_inc', 'int_rate', 'installment_ratio', 'emp_length', \n",
    "                'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc', 'pub_rec', \n",
    "                'revol_bal', 'revol_util', 'total_acc', 'collections_12_mths_ex_med', \n",
    "                'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim', \n",
    "                'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', \n",
    "                'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct', \n",
    "                'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', \n",
    "                'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_inq',\n",
    "                'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
    "                'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
    "                'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
    "                'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', \n",
    "                'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
    "                'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
    "                'total_il_high_credit_limit', 'credit_length']\n",
    "\n",
    "features = cat_features + num_features\n",
    "\n",
    "# define numerical and categorical features\n",
    "print('Categorical feature:\\t', len(cat_features))\n",
    "print('Numerical feature:\\t', len(num_features))\n",
    "print('Total feature:\\t\\t', len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. H2O Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize H2O cluster# # Ini \n",
    "h2o.init(nthreads=-1, max_mem_size='45G')\n",
    "h2o.remove_all()\n",
    "\n",
    "# Transform to H2O Frame, and make sure the target variable is categorical\n",
    "h2o_train = H2OFrame(train[features + ['target']])\n",
    "h2o_test = H2OFrame(test[features])\n",
    "\n",
    "# transform into categorical\n",
    "h2o_train['target'] = h2o_train['target'].asfactor()\n",
    "\n",
    "for name in cat_feature:\n",
    "    h2o_train[name] = h2o_train[name].asfactor()\n",
    "    h2o_test[name] = h2o_test[name].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model with Lasso using grid search# # Tra \n",
    "hyper_parameters = {'alpha': [0, 0.2, 0.4, 0.6, 0.8, 1.0], \n",
    "                    'lambda': [0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]}\n",
    "\n",
    "# Create GLM model\n",
    "glm = H2OGeneralizedLinearEstimator(family='binomial', balance_classes=True, \n",
    "                                    early_stopping=True, custom_metric_func='auc',\n",
    "                                    keep_cross_validation_predictions=True, nfolds=5)\n",
    "\n",
    "# Grid search\n",
    "glm_grid = H2OGridSearch(glm, hyper_parameters, grid_id='GLM')\n",
    "glm_grid.train(x=features, y='TARGET', training_frame=h2o_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grid search result, sorted by AUC\n",
    "glm_models = glm_grid.get_grid(sort_by='auc', decreasing=True)\n",
    "\n",
    "# Choose the best model\n",
    "best_glm = glm_grid.models[0]\n",
    "\n",
    "glm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "glm_train_pred = best_glm.predict(h2o_train).as_data_frame()['p1'].values\n",
    "glm_test_pred = best_glm.predict(h2o_test).as_data_frame()['p1'].values\n",
    "\n",
    "# Build the ROC curve\n",
    "glm_fpr, glm_tpr, _ = roc_curve(train['TARGET'].values, glm_train_pred)\n",
    "glm_auc = np.round(auc(glm_fpr, glm_tpr), 3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(glm_fpr, glm_tpr, label='AUC: ' + str(glm_auc))\n",
    "ax.plot(glm_fpr, glm_fpr, 'k:')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction file\n",
    "test_id = test['SK_ID_CURR'].values\n",
    "test_pred = glm_test_pred\n",
    "\n",
    "glm_csv = pd.DataFrame({'SK_ID_CURR': test_id, 'TARGET': test_pred}, \n",
    "                       columns=['SK_ID_CURR', 'TARGET'])\n",
    "glm_csv.to_csv('./result/all_feature_h2o_logistic_regression_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build random forest model\n",
    "rf_model = H2ORandomForestEstimator(balance_classes=True, ntrees=1000, max_depth=20, \n",
    "                                    mtries=-1, seed=42, score_each_iteration=True)\n",
    "rf_model.train(x=features, y='TARGET', training_frame=h2o_train)\n",
    "\n",
    "# Make prediction\n",
    "rf_test_pred = rf_model.predict(h2o_test).as_data_frame()['p1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance = rf_model.varimp(use_pandas=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.barplot(x='scaled_importance', y='variable', data=importance[:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction file\n",
    "test_id = test['SK_ID_CURR'].values\n",
    "test_pred = rf_test_pred\n",
    "\n",
    "rf_csv = pd.DataFrame({'SK_ID_CURR': test_id, 'TARGET': test_pred}, \n",
    "                       columns=['SK_ID_CURR', 'TARGET'])\n",
    "rf_csv.to_csv('./result/all_feature_h2o_random_forest_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shutdown h2o instance\n",
    "# h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. LightGBM Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical data into numerical format\n",
    "label_encoders = []\n",
    "for name in cat_feature:\n",
    "    encoder = LabelEncoder()\n",
    "    train[name] = encoder.fit_transform(train[name])\n",
    "    test[name] = encoder.transform(test[name])\n",
    "    label_encoders.append(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LightGBM dataset\n",
    "train_x = train[features]\n",
    "train_y = train['TARGET'].values\n",
    "\n",
    "gbm_train = lgb.Dataset(data=train_x, label=train_y, feature_name=features, \n",
    "                        categorical_feature=cat_feature, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter space to explore\n",
    "rf_max_bin_list = [255, 300]\n",
    "rf_num_leaves_list = [20, 30, 40, 50, 60]\n",
    "rf_max_depth_list = [-1, 20, 30, 40, 50]\n",
    "rf_min_data_in_leaf_list = [20, 30, 40, 50]\n",
    "rf_bagging_frac_list = [0.5, 0.632, 0.7, 0.8]\n",
    "rf_feature_frac_list = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "rf_max_bin_vals = []\n",
    "rf_num_leaves_vals = []\n",
    "rf_max_depth_vals = []\n",
    "rf_min_data_vals = []\n",
    "rf_bagging_frac_vals = []\n",
    "rf_feature_frac_vals = []\n",
    "\n",
    "rf_mean_auc = []\n",
    "rf_std_auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search with Cross validation\n",
    "s = '|{0:>7s} |{1:>10s} |{2:>10s} |{3:>16s} |{4:>16s} |{5:>16s} |{6:>6s} |{7:>6s} |'\n",
    "print(s.format('max_bin', 'num_leaves', 'max_depth', 'min_data_in_leaf', \n",
    "               'bagging_fraction', 'feature_fraction', 'AUC', 'std'))\n",
    "print('-' * 104)\n",
    "\n",
    "# perform random search for given number n\n",
    "n = 30\n",
    "np.random.seed(42)\n",
    "visited = set()\n",
    "for i in range(n):\n",
    "    while True:\n",
    "        max_bin = np.random.choice(rf_max_bin_list)\n",
    "        num_leaves = np.random.choice(rf_num_leaves_list)\n",
    "        max_depth = np.random.choice(rf_max_depth_list)\n",
    "        min_data_in_leaf = np.random.choice(rf_min_data_in_leaf_list)\n",
    "        bagging_fraction = np.random.choice(rf_bagging_frac_list)\n",
    "        feature_fraction = np.random.choice(rf_feature_frac_list)\n",
    "        \n",
    "        tuples = (max_bin, num_leaves, max_depth, min_data_in_leaf, \n",
    "                  bagging_fraction, feature_fraction)\n",
    "        if tuples not in visited:\n",
    "            visited.add(tuples)\n",
    "            break\n",
    "            \n",
    "    params = {'objective': 'binary', \n",
    "              'boosting': 'rf', \n",
    "              'num_threads': 4, \n",
    "              'is_unbalance': True, \n",
    "              'metric': ['auc'],\n",
    "              'learning_rate': 0.1, \n",
    "              'max_bin': max_bin, \n",
    "              'num_leaves': num_leaves, \n",
    "              'max_depth': max_depth, \n",
    "              'min_data_in_leaf': min_data_in_leaf, \n",
    "              'bagging_fraction': bagging_fraction, \n",
    "              'feature_fraction': feature_fraction, \n",
    "              'bagging_freq': 1, \n",
    "              'lambda_l1': 0.0,\n",
    "              'lambda_l2': 0.0,\n",
    "              'drop_rate': 0.1}\n",
    "\n",
    "    # 5-folder cross validation (no early stopping)\n",
    "    history = lgb.cv(params, train_set=gbm_train, nfold=5, num_boost_round=500, \n",
    "                     stratified=True, early_stopping_rounds=None, verbose_eval=False, \n",
    "                     seed=42, feature_name=features, categorical_feature=cat_feature)\n",
    "\n",
    "    # get result\n",
    "    rf_max_bin_vals.append(max_bin)\n",
    "    rf_num_leaves_vals.append(num_leaves)\n",
    "    rf_max_depth_vals.append(max_depth)\n",
    "    rf_min_data_vals.append(min_data_in_leaf)\n",
    "    rf_bagging_frac_vals.append(bagging_fraction)\n",
    "    rf_feature_frac_vals.append(feature_fraction)\n",
    "    rf_mean_auc.append(history['auc-mean'][-1])\n",
    "    rf_std_auc.append(history['auc-stdv'][-1])\n",
    "        \n",
    "    # output the resuts\n",
    "    ss = '|{0:7d} |{1:10d} |{2:10d} |{3:16d} |{4:16.4f} |{5:16.4f} |{6:6.4f} |{7:6.4f} |'\n",
    "    print(ss.format(max_bin, num_leaves, max_depth, min_data_in_leaf, bagging_fraction, \n",
    "                    feature_fraction, history['auc-mean'][-1], history['auc-stdv'][-1]))\n",
    "    \n",
    "# get the best parameters\n",
    "idx = np.argmax(rf_mean_auc)\n",
    "print('-' * 104)\n",
    "print(ss.format(rf_max_bin_vals[idx], rf_num_leaves_vals[idx], rf_max_depth_vals[idx], \n",
    "                rf_min_data_vals[idx], rf_bagging_frac_vals[idx], rf_feature_frac_vals[idx], \n",
    "                rf_mean_auc[idx], rf_std_auc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define best parameters\n",
    "params = {'objective': 'binary', \n",
    "          'boosting': 'rf', \n",
    "          'num_threads': 4, \n",
    "          'is_unbalance': True, \n",
    "          'metric': ['auc'],\n",
    "          'learning_rate': 0.1, \n",
    "          'max_bin': 255, \n",
    "          'num_leaves': 60, \n",
    "          'max_depth': -1, \n",
    "          'min_data_in_leaf': 30, \n",
    "          'bagging_fraction': 0.7, \n",
    "          'feature_fraction': 0.4, \n",
    "          'bagging_freq': 1, \n",
    "          'lambda_l1': 0.0,\n",
    "          'lambda_l2': 0.0,\n",
    "          'drop_rate': 0.1}\n",
    "\n",
    "# re-train the model and make predictions\n",
    "rf = lgb.train(params, train_set=gbm_train, num_boost_round=1000, \n",
    "               feature_name=features, categorical_feature=cat_feature)\n",
    "rf_test_pred = rf.predict(test[features])\n",
    "\n",
    "# feature importance\n",
    "importance = rf.feature_importance()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "lgb.plot_importance(rf, ax=ax, height=0.5, max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance details\n",
    "rf_importance = pd.DataFrame({'feature': features, 'importance': importance}, \n",
    "                             columns=['feature', 'importance'])\n",
    "rf_importance = rf_importance.sort_values(by='importance', ascending=False)\n",
    "rf_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction files\n",
    "test_id = test['SK_ID_CURR'].values\n",
    "test_pred = rf_test_pred\n",
    "\n",
    "rf_csv = pd.DataFrame({'SK_ID_CURR': test_id, 'TARGET': test_pred}, \n",
    "                       columns=['SK_ID_CURR', 'TARGET'])\n",
    "rf_csv.to_csv('./result/all_feature_lightGBM_random_forest_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter space to explore\n",
    "gbm_learning_rate_list = [0.001, 0.01, 0.1]\n",
    "gbm_max_bin_list = [255, 400]\n",
    "gbm_num_leaves_list = [20, 30, 40, 50, 60]\n",
    "gbm_max_depth_list = [-1, 20, 30, 40, 50]\n",
    "gbm_min_data_in_leaf_list = [20, 30, 40, 50]\n",
    "\n",
    "gbm_learning_rate_vals = []\n",
    "gbm_max_bin_vals = []\n",
    "gbm_num_leaves_vals = []\n",
    "gbm_max_depth_vals = []\n",
    "gbm_min_data_vals = []\n",
    "\n",
    "gbm_best_rounds = []\n",
    "gbm_mean_auc = []\n",
    "gbm_std_auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search with Cross validation\n",
    "s = '|{0:>13s} |{1:>7s} |{2:>10s} |{3:>10s} |{4:>16s} | {5:>12s}| {6:>6s} |{7:>6s} |'\n",
    "print(s.format('learning_rate', 'max_bin', 'num_leaves', 'max_depth', \n",
    "               'min_data_in_leaf', 'best_rounds', 'AUC', 'std'))\n",
    "print('-' * 98)\n",
    "\n",
    "# perform random search for given number n\n",
    "n = 30\n",
    "np.random.seed(42)\n",
    "visited = set()\n",
    "for i in range(n):\n",
    "    while True:\n",
    "        learning_rate = np.random.choice(gbm_learning_rate_list)\n",
    "        max_bin = np.random.choice(gbm_max_bin_list)\n",
    "        num_leaves = np.random.choice(gbm_num_leaves_list)\n",
    "        max_depth = np.random.choice(gbm_max_depth_list)\n",
    "        min_data_in_leaf = np.random.choice(gbm_min_data_in_leaf_list)\n",
    "        \n",
    "        tuples = (learning_rate, max_bin, num_leaves, max_depth, min_data_in_leaf)\n",
    "        if tuples not in visited:\n",
    "            visited.add(tuples)\n",
    "            break\n",
    "            \n",
    "    params = {'objective': 'binary', \n",
    "              'boosting': 'gbdt', \n",
    "              'num_threads': 4, \n",
    "              'is_unbalance': True, \n",
    "              'metric': ['auc'],\n",
    "              'learning_rate': learning_rate, \n",
    "              'max_bin': max_bin, \n",
    "              'num_leaves': num_leaves, \n",
    "              'max_depth': max_depth, \n",
    "              'min_data_in_leaf': min_data_in_leaf, \n",
    "              'bagging_fraction': 1.0, \n",
    "              'feature_fraction': 1.0, \n",
    "              'bagging_freq': 0, \n",
    "              'lambda_l1': 0.0,\n",
    "              'lambda_l2': 0.0,\n",
    "              'drop_rate': 0.1}\n",
    "\n",
    "    # 5-folder cross validation (no early stopping)\n",
    "    history = lgb.cv(params, train_set=gbm_train, nfold=5, num_boost_round=1000, \n",
    "                     stratified=True,  early_stopping_rounds=30, verbose_eval=False, \n",
    "                     seed=42, feature_name=features, categorical_feature=cat_feature)\n",
    "\n",
    "    # get result\n",
    "    gbm_learning_rate_vals.append(learning_rate)\n",
    "    gbm_max_bin_vals.append(max_bin)\n",
    "    gbm_num_leaves_vals.append(num_leaves)\n",
    "    gbm_max_depth_vals.append(max_depth)\n",
    "    gbm_min_data_vals.append(min_data_in_leaf)\n",
    "    gbm_best_rounds.append(len(history['auc-mean']))\n",
    "    gbm_mean_auc.append(history['auc-mean'][-1])\n",
    "    gbm_std_auc.append(history['auc-stdv'][-1])\n",
    "        \n",
    "    # output the resuts\n",
    "    ss = '|{0:>13.5f} |{1:>7d} |{2:>10d} |{3:>10d} |{4:>16d} | {5:>12d}| {6:>6.4f} |{7:>6.4f} |'\n",
    "    print(ss.format(learning_rate, max_bin, num_leaves, max_depth, min_data_in_leaf, \n",
    "                    len(history['auc-mean']), history['auc-mean'][-1], history['auc-stdv'][-1]))\n",
    "    \n",
    "# get the best parameters\n",
    "idx = np.argmax(gbm_mean_auc)\n",
    "print('-' * 104)\n",
    "print(ss.format(gbm_learning_rate_vals[idx], gbm_max_bin_vals[idx], gbm_num_leaves_vals[idx], \n",
    "                gbm_max_depth_vals[idx], gbm_min_data_vals[idx], gbm_best_rounds[idx], \n",
    "                gbm_mean_auc[idx], gbm_std_auc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define best parameters\n",
    "params = {'objective': 'binary', \n",
    "          'boosting': 'gbdt', \n",
    "          'num_threads': 4, \n",
    "          'is_unbalance': True, \n",
    "          'metric': ['auc'],\n",
    "          'learning_rate': 0.1, \n",
    "          'max_bin': 255, \n",
    "          'num_leaves': 50, \n",
    "          'max_depth': -1, \n",
    "          'min_data_in_leaf': 40, \n",
    "          'bagging_fraction': 1.0, \n",
    "          'feature_fraction': 1.0,\n",
    "          'bagging_freq': 0,\n",
    "          'lambda_l1': 0.0,\n",
    "          'lambda_l2': 0.0,\n",
    "          'drop_rate': 0.1}\n",
    "\n",
    "# re-train the model and make predictions\n",
    "gbm = lgb.train(params, train_set=gbm_train, num_boost_round=997, \n",
    "                feature_name=features, categorical_feature=cat_feature)\n",
    "gbm_test_pred = gbm.predict(test[features])\n",
    "\n",
    "# feature importance\n",
    "importance = gbm.feature_importance()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "lgb.plot_importance(gbm, ax=ax, height=0.5, max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance details\n",
    "gbm_importance = pd.DataFrame({'feature': features, 'importance': importance}, \n",
    "                             columns=['feature', 'importance'])\n",
    "gbm_importance = gbm_importance.sort_values(by='importance', ascending=False)\n",
    "gbm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction files\n",
    "test_id = test['SK_ID_CURR'].values\n",
    "test_pred = gbm_test_pred\n",
    "\n",
    "gbm_csv = pd.DataFrame({'SK_ID_CURR': test_id, 'TARGET': test_pred}, \n",
    "                       columns=['SK_ID_CURR', 'TARGET'])\n",
    "gbm_csv.to_csv('./result/all_feature_lightGBM_boosting_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. CatBoost Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Pool object\n",
    "train_pool = Pool(data=train[features], label=train['TARGET'].values, \n",
    "                  feature_names=features, cat_features=np.array(range(len(cat_feature))))\n",
    "\n",
    "test_pool = Pool(data=test[features], feature_names=features, \n",
    "                 cat_features=np.array(range(len(cat_feature))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train['TARGET'].values\n",
    "print('Negative class:\\t', sum(train_labels == 0))\n",
    "print('Positive class:\\t', sum(train_labels == 1))\n",
    "print('Neg / Pos:\\t', sum(train_labels == 0) / sum(train_labels == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter space to explore\n",
    "learning_rate_list = [0.03, 0.05, 0.08, 0.1]\n",
    "depth_list = [4, 5, 6, 7, 8, 9, 10]\n",
    "l2_leaf_reg_list = [1, 3, 5, 7, 9]\n",
    "random_strength_list = [0.1, 0.5, 1, 2]\n",
    "bagging_temperature_list = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "learning_rate_values = []\n",
    "depth_values = []\n",
    "l2_leaf_reg_values = []\n",
    "random_strength_values = []\n",
    "bagging_temperature_values = []\n",
    "\n",
    "best_iterations_values = []\n",
    "train_mean_auc_values = []\n",
    "train_auc_std_values = []\n",
    "test_mean_auc_values = []\n",
    "test_auc_std_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search with Cross validation\n",
    "s = '|{0:>13s} |{1:>5s} |{2:>11s} |{3:>15s} |{4:>19s} |{5:>10s} |{6:>9s} |{7:>9s} |'\n",
    "print(s.format('learning_rate', 'depth', 'l2_leaf_reg', 'random_strength', \n",
    "               'bagging_temperature', 'iterations', 'train_AUC', 'test_AUC'))\n",
    "print('-' * 108)\n",
    "\n",
    "# perform random search for given number n\n",
    "n = 30\n",
    "np.random.seed(42)\n",
    "visited = set()\n",
    "for i in range(n):\n",
    "    while True:\n",
    "        learning_rate = np.random.choice(learning_rate_list)\n",
    "        depth = np.random.choice(depth_list)\n",
    "        l2_leaf_reg = np.random.choice(l2_leaf_reg_list)\n",
    "        random_strength = np.random.choice(random_strength_list)\n",
    "        bagging_temperature = np.random.choice(bagging_temperature_list)\n",
    "        \n",
    "        tuples = (learning_rate, depth, l2_leaf_reg, random_strength, bagging_temperature)\n",
    "        if tuples not in visited:\n",
    "            visited.add(tuples)\n",
    "            break\n",
    "            \n",
    "    # define parameters\n",
    "    params = {'loss_function': 'Logloss', \n",
    "              'custom_metric': 'AUC', \n",
    "              'eval_metric': 'AUC',\n",
    "              'learning_rate': learning_rate, \n",
    "              'depth': depth, \n",
    "              'l2_leaf_reg': l2_leaf_reg,\n",
    "              'random_strength': random_strength, \n",
    "              'bagging_temperature': bagging_temperature, \n",
    "              'random_seed': 42, \n",
    "              'bootstrap_type': 'Bayesian', \n",
    "              'has_time': False, \n",
    "              'class_weights': [1, 11]}\n",
    "\n",
    "    scores = cv(pool=train_pool, params=params, iterations=1000, fold_count=5,\n",
    "                seed=42, shuffle=True, logging_level='Silent', stratified=True,\n",
    "                as_pandas=False, metric_period=1, early_stopping_rounds=10)\n",
    "    \n",
    "    # get result\n",
    "    learning_rate_values.append(learning_rate)\n",
    "    depth_values.append(depth)\n",
    "    l2_leaf_reg_values.append(l2_leaf_reg)\n",
    "    random_strength_values.append(random_strength)\n",
    "    bagging_temperature_values.append(bagging_temperature)\n",
    "    \n",
    "    best_idx = np.argmax(scores['test-AUC-mean'])\n",
    "    best_iterations = best_idx + 1\n",
    "    train_mean_auc = scores['train-AUC-mean'][best_idx]\n",
    "    train_auc_std = scores['train-AUC-std'][best_idx]\n",
    "    test_mean_auc = scores['test-AUC-mean'][best_idx]\n",
    "    test_auc_std = scores['test-AUC-std'][best_idx]\n",
    "    \n",
    "    best_iterations_values.append(best_iterations)\n",
    "    train_mean_auc_values.append(train_mean_auc)\n",
    "    train_auc_std_values.append(train_auc_std)\n",
    "    test_mean_auc_values.append(test_mean_auc)\n",
    "    test_auc_std_values.append(test_auc_std)\n",
    "    \n",
    "    # output the resuts\n",
    "    ss = '|{0:>13.4f} |{1:>5d} |{2:>11d} |{3:>15.4f} |{4:>19.4f} |{5:>10d} |{6:>9.4f} |{7:>9.4f} |'\n",
    "    print(ss.format(learning_rate, depth, l2_leaf_reg, random_strength, bagging_temperature, \n",
    "                    best_iterations, train_mean_auc, test_mean_auc))\n",
    "    \n",
    "# get the best parameters\n",
    "idx = np.argmax(test_mean_auc_values)\n",
    "print('-' * 108)\n",
    "print(ss.format(learning_rate_values[idx], depth_values[idx], l2_leaf_reg_values[idx], \n",
    "                random_strength_values[idx], bagging_temperature_values[idx], \n",
    "                best_iterations_values[idx], train_mean_auc_values[idx], \n",
    "                test_mean_auc_values[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build CatBoost classifier\n",
    "model = CatBoostClassifier(loss_function='Logloss', custom_metric='AUC', eval_metric='AUC',\n",
    "                           learning_rate=0.05, depth=5, l2_leaf_reg=7, random_strength=0.5, \n",
    "                           bagging_temperature=1.0, iterations=869, random_seed=42, \n",
    "                           class_weights=[1, 11], bootstrap_type='Bayesian', subsample=None,\n",
    "                           use_best_model=None, ignored_features=None, one_hot_max_size=None, \n",
    "                           has_time=False, rsm=None, nan_mode=None, leaf_estimation_iterations=None, \n",
    "                           leaf_estimation_method=None, boosting_type=None, allow_const_label=None)\n",
    "\n",
    "model.fit(X=train_pool, eval_set=None, logging_level='Verbose', plot=False, \n",
    "          column_description=None, metric_period=50, early_stopping_rounds=None)\n",
    "\n",
    "catboost_test_pred = model.predict_proba(data=test_pool)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction files\n",
    "test_id = test['SK_ID_CURR'].values\n",
    "test_pred = catboost_test_pred\n",
    "\n",
    "catboost_csv = pd.DataFrame({'SK_ID_CURR': test_id, 'TARGET': test_pred}, \n",
    "                            columns=['SK_ID_CURR', 'TARGET'])\n",
    "catboost_csv.to_csv('./result/all_feature_boosting_catboost_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
